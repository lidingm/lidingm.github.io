<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>[论文学习]ATTEMPT:通过注意力混合软提示进行参数高效的多任务调整 | 碎碎念的博客</title><meta name="author" content="Dingming Li"><meta name="copyright" content="Dingming Li"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="论文学习：ATTEMPT:通过注意力混合软提示进行参数高效的多任务调整资料 论文：ATTEMPT: Parameter-Efficient Multi-task Tuning via Attentional Mixtures of Soft Prompts 代码：AkariAsai&#x2F;ATTEMPT: This is the oficial repository for “Parameter-Eff">
<meta property="og:type" content="article">
<meta property="og:title" content="[论文学习]ATTEMPT:通过注意力混合软提示进行参数高效的多任务调整">
<meta property="og:url" content="http://example.com/2024/11/08/[%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0]ATTEMPT-%E9%80%9A%E8%BF%87%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%B7%B7%E5%90%88%E8%BD%AF%E6%8F%90%E7%A4%BA%E8%BF%9B%E8%A1%8C%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E8%B0%83%E6%95%B4/index.html">
<meta property="og:site_name" content="碎碎念的博客">
<meta property="og:description" content="论文学习：ATTEMPT:通过注意力混合软提示进行参数高效的多任务调整资料 论文：ATTEMPT: Parameter-Efficient Multi-task Tuning via Attentional Mixtures of Soft Prompts 代码：AkariAsai&#x2F;ATTEMPT: This is the oficial repository for “Parameter-Eff">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/img/butterfly-icon.png">
<meta property="article:published_time" content="2024-11-08T00:37:12.000Z">
<meta property="article:modified_time" content="2025-01-22T10:19:32.418Z">
<meta property="article:author" content="Dingming Li">
<meta property="article:tag" content="参数高效微调">
<meta property="article:tag" content="LLM">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img/butterfly-icon.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "[论文学习]ATTEMPT:通过注意力混合软提示进行参数高效的多任务调整",
  "url": "http://example.com/2024/11/08/[%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0]ATTEMPT-%E9%80%9A%E8%BF%87%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%B7%B7%E5%90%88%E8%BD%AF%E6%8F%90%E7%A4%BA%E8%BF%9B%E8%A1%8C%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E8%B0%83%E6%95%B4/",
  "image": "http://example.com/img/butterfly-icon.png",
  "datePublished": "2024-11-08T00:37:12.000Z",
  "dateModified": "2025-01-22T10:19:32.418Z",
  "author": [
    {
      "@type": "Person",
      "name": "Dingming Li",
      "url": "http://example.com/"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://example.com/2024/11/08/[%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0]ATTEMPT-%E9%80%9A%E8%BF%87%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%B7%B7%E5%90%88%E8%BD%AF%E6%8F%90%E7%A4%BA%E8%BF%9B%E8%A1%8C%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E8%B0%83%E6%95%B4/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '[论文学习]ATTEMPT:通过注意力混合软提示进行参数高效的多任务调整',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 7.3.0"></head><body><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">碎碎念的博客</span></a><a class="nav-page-title" href="/"><span class="site-name">[论文学习]ATTEMPT:通过注意力混合软提示进行参数高效的多任务调整</span></a></span><div id="menus"></div></nav><div id="post-info"><h1 class="post-title">[论文学习]ATTEMPT:通过注意力混合软提示进行参数高效的多任务调整</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-11-08T00:37:12.000Z" title="发表于 2024-11-08 08:37:12">2024-11-08</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-01-22T10:19:32.418Z" title="更新于 2025-01-22 18:19:32">2025-01-22</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0/">论文学习</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h1 id="论文学习：ATTEMPT-通过注意力混合软提示进行参数高效的多任务调整"><a href="#论文学习：ATTEMPT-通过注意力混合软提示进行参数高效的多任务调整" class="headerlink" title="论文学习：ATTEMPT:通过注意力混合软提示进行参数高效的多任务调整"></a>论文学习：ATTEMPT:通过注意力混合软提示进行参数高效的多任务调整</h1><h2 id="资料"><a href="#资料" class="headerlink" title="资料"></a>资料</h2><blockquote>
<p>论文：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2205.11961">ATTEMPT: Parameter-Efficient Multi-task Tuning via Attentional Mixtures of Soft Prompts</a></p>
<p>代码：<a target="_blank" rel="noopener" href="https://github.com/AkariAsai/ATTEMPT">AkariAsai/ATTEMPT: This is the oficial repository for “Parameter-Efficient Multi-task Tuning via Attentional Mixtures of Soft Prompts”</a></p>
</blockquote>
<h2 id="前置知识"><a href="#前置知识" class="headerlink" title="前置知识"></a>前置知识</h2><p>由于本文研究的核心问题是如何以参数高效的方式调整预训练模型，使其能够跨任务传递知识，同时保持或提高任务性能。ATTEMPT方法即通过使用注意力机制混合软提示来实现参数高效的多任务调整。</p>
<p>我们需要首先了解其他的参数高效微调方法，用以对比学习，并且文章也给出了ATTEMPT方法与其他微调方法的效果对比，所以我们先了解各个经典微调算法的原理用以区分学习。</p>
<h3 id="高效参数微调"><a href="#高效参数微调" class="headerlink" title="高效参数微调"></a>高效参数微调</h3><p>参数高效微调是指微调少量或额外的模型参数，固定大部分预训练模型参数，较于全量参数微调从而大大降低了计算和存储成本，同时，也能实现与全量参数微调相当的性能。</p>
<p>高效微调技术可以粗略分为以下三大类：增加额外参数（A）、选取一部分参数更新（S）、引入重参数化（R）。而在增加额外参数这类方法中，又主要分为类适配器（Adapter-like）方法和软提示（Soft prompts）两个小类。分类如下：</p>
<p><img src="https://cdn.jsdelivr.net/gh/lidingm/blog_img/img/202411081033196.png" alt="img"></p>
<p>接下来我们简单介绍下BitFit、Prefix Tuning、Prompt Tuning、P-Tuning、P-tuning -v2、SPoT。</p>
<p>在此之前我们需要理解什么是hard prompt与soft prompt：</p>
<ul>
<li>hard prompt (离散)：即人类写的自然语言式的prompt。</li>
<li>soft prompt (连续)：可训练的权重，可以理解为伪prompt。（毕竟LM是连续的模型，在连续空间中优化离散的prompt， 难以优化到最佳效果。额也就是说所谓的hard prompt对于人类来说好理解，但模型不一定好理解，所以不妨丢给模型去学习处更好理解的prompt）</li>
</ul>
<h3 id="BitFit"><a href="#BitFit" class="headerlink" title="BitFit"></a>BitFit</h3><p><strong>原理</strong>：对微调机制的一种积极探索，也很简单，通过仅调整bias效果就能有不错的效果，但没有具体阐述原理，就是通过猜测加实验得到的结果。同时，作者提出一个观点：微调的过程不是让模型适应另外的数据分布，而是让模型更好的应用出本身的表征能力。</p>
<p><strong>特点</strong>：</p>
<ul>
<li>训练参数量极小（约0.1%）。</li>
<li>在大部分任务上效果会差于LoRA、Adapter等方法。</li>
</ul>
<h3 id="Prefix-Tuning"><a href="#Prefix-Tuning" class="headerlink" title="Prefix Tuning"></a>Prefix Tuning</h3><p><strong>原理</strong>：在每一个Transformer层都带上一些virtual token作为前缀，以适应不同的任务。</p>
<p><strong>特点</strong>：</p>
<ul>
<li>前缀Token会占用序列长度，有一定的额外计算开销。</li>
<li>Prefix Tuning的线性插值是比较复杂的。</li>
</ul>
<h3 id="Prompt-Tuning"><a href="#Prompt-Tuning" class="headerlink" title="Prompt Tuning"></a>Prompt Tuning</h3><p><strong>原理</strong>：该方法可以看着是Prefix Tuning的简化版本，针对不同的任务，仅在输入层引入virtual token形式的软提示（soft prompt）。</p>
<p><strong>特点</strong>：</p>
<ul>
<li>相对于Prefix Tuning，参与训练的参数量和改变的参数量更小，更节省显存。</li>
<li>对一些简单的NLU 任务还不错，但对硬序列标记任务（即序列标注）表现欠佳。</li>
</ul>
<h3 id="P-Tuning"><a href="#P-Tuning" class="headerlink" title="P-Tuning"></a>P-Tuning</h3><p><strong>原理</strong>：将Prompt转换为可以学习的Embedding层，并用MLP+LSTM的方式来对Prompt Embedding进行一层处理。相比Prefix Tuning，仅在输入层加入的可微的virtual token；另外，virtual token的位置也不一定是前缀，插入的位置是可选的。</p>
<p><strong>特点</strong>：</p>
<ul>
<li>引入一个prompt encoder（由一个双向的LSTM+两层MLP组成）来建模virtual token的相互依赖会收敛更快，效果更好。</li>
</ul>
<h3 id="P-Tuning-v2"><a href="#P-Tuning-v2" class="headerlink" title="P-Tuning v2"></a>P-Tuning v2</h3><p><strong>原理</strong>：该方法在每一个Transformer层都加入了prompt token作为输入，引入多任务学习，针对不同任务采用不同的提示长度。并且回归传统的分类标签范式，而不是映射器。</p>
<p><strong>特点</strong>：</p>
<ul>
<li>解决了Prompt Tuning无法在小模型上有效提升的问题。</li>
<li>移除了对模型效果改进较小的重参数化的编码器（如：Prefix Tuning中的MLP、P-Tuning中的LSTM）。</li>
<li>对于一些复杂的硬序列标记任务（即序列标注）取得了不错的效果。</li>
</ul>
<h3 id="SPoT"><a href="#SPoT" class="headerlink" title="SPoT"></a>SPoT</h3><p><strong>原理</strong>：在之前P-tuning方法的基础上，提出的一种基于提示的迁移学习方法。它通过在一个或多个源任务上学习提示，然后将这些提示用于初始化目标任务的提示。具体来说，就是先为每个源任务生成提示，得到它们的任务表示，再计算这些表示与目标任务的相似度，选择最相似的k个源任务提示，将它们加权组合来初始化目标任务的提示，最后在目标任务上进行微调，以获得更适合的提示。</p>
<p><strong>特点</strong>：</p>
<ul>
<li>核心思想是在一个或多个源任务上学习提示，然后将学到的提示用于初始化目标任务的提示。</li>
<li>进行了大规模和系统的任务迁移能力研究，展示了任务通过提示转移相互受益的条件。</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/lidingm/blog_img/img/202411101201928.png" alt="image-20241110120153851"></p>
<h2 id="论文大体介绍"><a href="#论文大体介绍" class="headerlink" title="论文大体介绍"></a>论文大体介绍</h2><p>本文提出了一种名为ATTEMPT的新<strong>参数高效微调</strong>的方法，旨在通过<strong>注意力机制</strong>产生<strong>soft prompt</strong>、结合<strong>多任务学习</strong>，实现参数高效的语言模型微调。</p>
<p>具体来说，ATTEMPT通过注意力模块来混合源任务的软提示和目标任务的新初始化提示，以生成适用于每个目标任务实例的提示，使在不同任务间传递知识，在训练过程中，只有目标任务的提示和注意力权重会被更新，而原始的语言模型和源提示保持不变。</p>
<p>该方法不仅提高了训练效率，还能在资源有限的情况下实现高性能。且ATTEMPT通过模块化的方式，可以灵活地增加或移除源任务提示，从而有效地实现知识转移。实验表明，该方法在多项NLP任务中表现优异，尤其是在小样本学习场景下。</p>
<h2 id="论文背景"><a href="#论文背景" class="headerlink" title="论文背景"></a>论文背景</h2><p><strong>Fine-tuning：</strong>例如全参微调，在目标任务训练数据上微调大型语言模型的所有参数，然而，这种方法计算成本高，并且可能无法充分利用其他NLP任务的大量数据。</p>
<p><strong>参数高效的微调方法：</strong>近期的研究提出了一些参数高效的调整方法，这些方法只更新一小部分LM参数以适应目标任务。这里提到了prefix tuning、prompt tuning、in-context learning、SPoT。随着LMs的参数提升，更高的微调方法要求迫切。</p>
<p><strong>多任务学习与知识传递：</strong>多任务学习方法试图通过更新LM参数来学习新的目标任务，这些方法在NLP中被证明是有效的。但是，这些方法缺乏添加或移除源任务的灵活性。</p>
<p><strong>Soft Prompts：</strong>软提示是一种参数高效的方法，它通过在输入前添加可训练的提示来调整模型。这种方法保持了原始LM的冻结状态，并且可以灵活地添加或移除源提示，以实现有效的知识传递。</p>
<h2 id="方法原理"><a href="#方法原理" class="headerlink" title="方法原理"></a>方法原理</h2><p>ATTEMPT通过注意力模块来混合源任务的软提示和目标任务的新初始化提示，以生成适用于每个目标任务实例的提示，使在不同任务间传递知识。</p>
<p><img src="https://cdn.jsdelivr.net/gh/lidingm/blog_img/img/202411091443724.png" alt="image-20241109144342646"></p>
<p><strong>源提示预训练</strong>：ATTEMPT首先在大规模的源任务上预训练可转移的soft promp，这些提示作为小的嵌入向量，编码了源任务的知识，可能对其他任务有益，能够捕捉任务相关的知识。</p>
<p><strong>目标提示训练</strong>：通过将注意力加权的源提示和目标提示相结合，生成适用于每个输入实例的特定提示 <script type="math/tex">P_{instance}</script>。在训练过程中，新的任务提示<script type="math/tex">P_{target}</script>和注意力模块G通过<script type="math/tex">P_{instance}</script>进行更新，而源提示和原LM的参数则不进行更新，以保存从先前任务或预训练中学习到的知识。其分为以下模块：</p>
<ul>
<li><p>注意力权重计算：</p>
<p>​    为目标任务初始化一个新的 <script type="math/tex">P_{target}</script> ，之后使用注意力模块  G 计算输入 X 与提示（包括源提示和目标提示）之间的注意力权重，这个注意力模块G是一个轻量级的网络，可以在多任务训练中共享和同时训练。输入时的 X 和每个提示prompt进行最大池化操作，以获得固定长度的表示。进而利用轻量级的网络 G 对输入进行投影，生成注意力分布，提供之后使用到的注意力权重。</p>
</li>
<li><p>提示插值：</p>
<p>​    利用注意力权重对源提示和目标提示进行加权平均，生成最终的实例级提示：</p>
<script type="math/tex; mode=display">
P_{\text{instance}}(X) = P_{\text{target}} + \sum_{j=1}^{t+1} a_j P_j</script><p>​    其中，<script type="math/tex">a_j</script>是从注意力模块获得的权重，确保即使源任务不是很相关，也能保留目标提示的影响。</p>
</li>
</ul>
<p><strong>多任务训练与推理</strong>：训练中，ATTEMPT可以在多个目标任务上联合训练共享的注意力模块 G 和多个目标任务提示，将训练数据集合并，同时保留每个实例的任务ID信息。在训练中，根据实例的任务ID，生成对应实例级提示。每个目标任务提示的损失仅在提示被使用时进行反向传播，而注意力模块的权重在每次迭代中更新；</p>
<p>推理中，推理时仅需加载一次源提示、所有目标任务提示和共享的注意力模块 G。对于每个实例，检索对应的目标任务提示，将 <script type="math/tex">P_{instance}</script> 拼接到输入嵌入中，后续过程与prompt tuning相同。支持同时执行多个目标任务，显著减少推理时的模型加载开销。</p>
<p><strong>ATTEMPT参数效率</strong>：ATTEMPT和提示调优的一个独特特性是参数数量独立于语言模型层数。随着LMs规模增大，Adapter和 fine-tuning的参数数量会迅速增加，而ATTEMPT只更新软提示，不修改模型高层，从而在参数增长上保持适中。</p>
<p><strong>方法合理性评估</strong>：ATTEMPT方法合理地利用了注意力机制和软提示来实现参数高效的多任务学习，这与当前大型语言模型的发展趋势相符合。随着语言模型变得越来越大，全参数微调变得越来越不切实际。参数高效的微调方法如ATTEMPT，允许我们在资源有限的情况下，尽可能地利用大型模型。并且其方法在SPoT方法的基础上增加注意力机制，比相似度计算效果更好，更加灵活。</p>
<p><strong>假设与局限性评估</strong>：</p>
<ul>
<li><p>假设源任务与目标任务的相关性：源任务中的软提示能够捕捉到对目标任务有益的知识。那么这意味着源任务与目标任务之间存在一定的相关性，使得源任务中的知识和模式可以迁移到目标任务中。</p>
<p>局限性：如果源任务与目标任务之间的相关性很低，那么源任务的软提示可能不会为目标任务提供有用的信息，这可能会限制模型的性能。</p>
</li>
<li><p>假设注意力机制的有效性：注意力机制能够有效地从多个源提示中选择相关信息，那么其应该能够准确地识别出哪些源任务提示对当前目标任务最有帮助。</p>
<p>局限性：如果注意力机制不能正确地评估源提示的重要性，模型可能会忽略重要的信息，从而无法构建好的<script type="math/tex">P_{instance}</script>。</p>
</li>
</ul>
<h2 id="实验设置"><a href="#实验设置" class="headerlink" title="实验设置"></a>实验设置</h2><p><strong>源任务和目标任务</strong>：</p>
<ul>
<li><p>源任务：</p>
<p>选择了6个大规模数据集作为源任务，包括MNLI、QNLI、QQP、SST-2、SQuAD和ReCoRD。这些数据集提供丰富的知识用于预训练软提示。</p>
</li>
<li><p>目标任务：</p>
<p>在21个不同的目标任务上进行评估，包括GLUE和SuperGLUE中的任务（如BoolQ、CB、RTE等，来测试模型的自然语言处理能力）、问答任务（如Natural Questions、HotpotQA等），以及其他任务（如SciTail、Yelp-2等）。</p>
</li>
</ul>
<p><strong>基线测试和实现细节</strong>：</p>
<ul>
<li><p>基线方法：</p>
<p>比较了ATTEMPT与多种方法的性能，包括Fine tuning、prompt tuning、SPoT、Adapter、BitFit、以及多任务方法（如FT-multi-task (FT-m), Adapter-m, HyperFormerr等）。</p>
</li>
<li><p>实现细节：</p>
<p>方法 ATTEMPT 和 ATTEMPT-m 使用相同的六个源任务提示， ATTEMPT-m 通过进行多任务训 练在多个目标任务上训练一个共享注意力层，而 ATTEMPT 则分别训练特定任务的注意力层，并且使用T5-base作为基础语言模型、使用公共数据集的开发集或拆分出的测试集进行评估。</p>
</li>
<li><p>Prompt初始化：</p>
<p>每个源提示都是通过从顶级词汇中随机采样标记来初始化的。对于目标任务提示初始化，使用非问答任务的MNLI源提示和问答任务的SQuAD源提示，而不是用随机采样的词汇进行初始化，以保证训练的稳定性。</p>
</li>
</ul>
<h2 id="实验结论"><a href="#实验结论" class="headerlink" title="实验结论"></a>实验结论</h2><p><strong>整体性能</strong>：</p>
<ul>
<li><p>GLUE和SuperGLUE任务：</p>
<p>ATTEMPT - m显著优于PT、SPoT和BitFit，并与Adapter或Fine - Tuning匹配，尽管每个任务更新的参数要少得多</p>
</li>
<li><p>对prompt tuing进行了改进：</p>
<p>prompt tuing对超参数或初始化很敏感，并且在 诸如 CoLA、BoolQ或 WiC 等几个数据集上的表现显著降低。ATTEMPT在较小的数据集(例如, CB , RTE等)和大规模的MRQA数据集上的性能明显优于这些方法。</p>
</li>
</ul>
<p><strong>少样本域适应</strong>：通过共享注意力模块，ATTEMPT能够灵活组合不同任务的知识，提高了少样本学习的效率。在少样本任务上的表现优于其他方法，尤其是在资源受限的情况下，充分利用了源任务的知识进行有效的知识转移。在较小的数据集上具有特别强的竞争力。</p>
<p><strong>消融实验</strong>：通过消融实验，验证了注意力机制在实例级提示生成中的重要性，证明了其在提升模型性能上的关键作用；另外通过多任务共享注意力模块，显著提高了小样本任务的性能，展示了其在知识转移中的有效性。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>提出了一种新的参数高效微调方法 ATTEMPT，它通过在源任务上训练的多个可重用的软提示和一个新的特定任务提示之间进行插值来学习生成实例级提示，同时保持原始的语言模型冻结。大规模实验表明， ATTEMPT 在任务性能和效率之间实现了很好的平衡，引入了一种可解释且模块化的任务迁移。</p>
<p>以下是ATTEMPT方法与各微调方法之间的对比：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>特征</th>
<th>ATTEMPT</th>
<th>BitFit</th>
<th>Prefix Tuning</th>
<th>Prompt Tuning</th>
<th>P-Tuning</th>
<th>P-tuning-v2</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>参数更新</strong></td>
<td>仅更新目标任务的prompt和注意力权重</td>
<td>仅更新模型的偏置参数</td>
<td>更新prompt，但保持模型参数不变</td>
<td>更新soft prompt，保持模型参数不变</td>
<td>更新prompt，保持模型参数不变</td>
<td>更新prompt，保持模型参数不变</td>
</tr>
<tr>
<td><strong>多任务学习能力</strong></td>
<td>支持模块化多任务学习</td>
<td>不支持多任务学习</td>
<td>支持多任务学习</td>
<td>支持多任务学习</td>
<td>支持多任务学习</td>
<td>支持多任务学习</td>
</tr>
<tr>
<td><strong>知识迁移</strong></td>
<td>通过注意力机制有效整合多个任务的知识</td>
<td>无法进行知识迁移</td>
<td>可以实现知识迁移</td>
<td>可以实现知识迁移</td>
<td>通过任务间的迁移能力实现</td>
<td>通过任务间的迁移能力实现</td>
</tr>
<tr>
<td><strong>参数效率</strong></td>
<td>更新少量参数（约0.4%）</td>
<td>更新约280k参数</td>
<td>更新少量参数（约77k）</td>
<td>更新少量参数（约77k，0.01% ）</td>
<td>更新参数较少，具体依赖于使用的模型（0.01% ）</td>
<td>更新参数较少，具体依赖于使用的模型（0. 1%-3%）</td>
</tr>
<tr>
<td><strong>适用场景</strong></td>
<td>适合少量样本的任务及需要灵活组合知识的场景</td>
<td>适用于只需微调偏置的小规模任务</td>
<td>适用于快速任务适应</td>
<td>适用于任务的快速适应</td>
<td>适用于需要跨任务迁移学习的场景</td>
<td>适用于需要跨任务迁移学习的场景</td>
</tr>
<tr>
<td><strong>任务间相似性分析能力</strong></td>
<td>可生成注意力分布以理解任务间的相似性</td>
<td>无法分析任务间相似性</td>
<td>无法分析任务间相似性</td>
<td>无法分析任务间相似性</td>
<td>可通过分析prompt权重了解任务间相似性</td>
<td>可通过分析prompt权重了解任务间相似性</td>
</tr>
</tbody>
</table>
</div>
<div class="table-container">
<table>
<thead>
<tr>
<th>特性</th>
<th>SPoT</th>
<th>ATTEMPT</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>知识迁移</strong></td>
<td>是</td>
<td>是</td>
</tr>
<tr>
<td><strong>方法原理</strong></td>
<td>通过相似度与加权结合源任务提示初始化目标任务提示</td>
<td>引入注意力模块，动态结合源提示和目标提示</td>
</tr>
<tr>
<td><strong>多任务学习</strong></td>
<td>支持</td>
<td>支持，且使用共享的注意力模块</td>
</tr>
<tr>
<td><strong>参数更新</strong></td>
<td>更新目标任务提示</td>
<td>更新目标任务提示和注意力权重，保留原始模型和源提示</td>
</tr>
<tr>
<td><strong>模块化和灵活性</strong></td>
<td>一般</td>
<td>高，可通过预训练的软提示灵活添加或移除源提示</td>
</tr>
</tbody>
</table>
</div>
<h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><p><strong>参数效率与高性能</strong>：ATTEMPT通过仅更新目标任务的提示和注意力权重，显著减少了需要更新的参数数量，相比全参数微调，极大地降低了计算和存储成本。同时其在在多项NLP任务中表现优异，尤其是在小样本学习场景下，能够与全参数微调相媲美或超越。</p>
<p><strong>多任务学习与模块化</strong>：通过共享注意力模块，ATTEMPT能够同时处理多个目标任务，提高了小样本任务的性能，尤其是在资源受限的情况下。同时其允许灵活地添加或移除源任务提示，使得知识转移更加灵活和模块化，有助于构建强大的多任务模型。</p>
<h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><p><strong>内存占用与计算成本</strong>：但由于ATTEMPT方法通过在输入前添加soft prompt来调整模型，这个提示调整增加了输入标记的长度，从而增加了内存占用，可能会带来额外的计算成本。</p>
<p><strong>任务类型的限制</strong>：ATTEMPT方法主要针对分类和问答任务进行了评估，并没有涉及到需要长序列生成的任务。这意味着ATTEMPT在这些类型的任务上的有效性尚未得到验证。此外ATTEMPT在非英语任务上的有效性尚未得到测试。</p>
<p><strong>源任务组合的限制</strong>：虽然ATTEMPT展示了通过软提示传递知识的能力，但论文中的实验主要基于有限数量的源任务。对于更广泛的源任务组合，ATTEMPT的效果如何，还需要进一步的研究和实验来探索。</p>
<h3 id="改进"><a href="#改进" class="headerlink" title="改进"></a>改进</h3><p><strong>不同的注意力机制</strong>：对于注意力模块中注意力权重的计算，原公式如下：</p>
<script type="math/tex; mode=display">
a_j = \frac{e^{\hat{\mathbf{P}}_j \mathbf{H}_{\text{out}} / T}}{\sum_{k=1}^{t+1} e^{\hat{\mathbf{P}}_k \mathbf{H}_{\text{out}} / T}}</script><p>可以改为：</p>
<script type="math/tex; mode=display">
a_{lj} = \frac{e^{\hat{\mathbf{P}}_{lj} \mathbf{H}_{\text{out}}}}{\sum_{k=1}^{t+1} e^{\hat{\mathbf{P}}_{lk} \mathbf{H}_{\text{out}}}}</script><p>即这里，不是计算<script type="math/tex">H_{out}</script>的摘要表示与提示<script type="math/tex">P_j</script> 之间的相似度，而是计算<script type="math/tex">H_{out}</script>与第<script type="math/tex">l</script>个提示令牌之间的相似度，对于提示token级别的注意力，在右边的第二项中，将摘要表示中的每一个第<script type="math/tex">l</script>个提示令牌计算为第<script type="math/tex">l</script>个提示令牌的加权摘要。即其原计算使用最大池化来统一计算注意力分数，之后可以利用token级别的注意力计算，另外可以考虑引入更复杂的注意力机制用以捕捉不通任务的prompt之间的关系。</p>
<p><strong>深度提示优化</strong>：从文章中可以看出，生成的实例化软提示<script type="math/tex">P_{instance}</script>只是被插入到transformer第一层的输入embedding序列的前端，那么在接下来的transformer层中，插入连续提示的位置的embedding是由之前的transformer层计算出来的，会导致序列长度限制可调参数的数量，另外的输入embedding对模型预测只有相对间接的影响，所以可以在每一层都加入了实例化软提示<script type="math/tex">P_{instance}</script>作为输入。·</p>
<p><strong>重参数化的编码器</strong>：利用重参数化功能来提高训练速度和鲁棒性，如加入MLP与LSTM，查看效果的变化。</p>
<p><strong>扩展任务类型和源任务组合</strong>：由于其实验主要基于有限数量的源任务，那么我们可以通过增加更多的源任务类型和组合来提高模型的泛化能力，另外在其他语言任务上也可以做尝试。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/635152813">大模型参数高效微调技术原理综述（一）-背景、参数高效微调简介 - 知乎 (zhihu.com)</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/422921903">Prompt Tuning 近期研究进展 - 知乎 (zhihu.com)</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/618871247">五万字综述！Prompt-Tuning：深度解读一种新的微调范式 - 知乎 (zhihu.com)</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_39328436/article/details/122951888?ops_request_misc=%7B%22request%5Fid%22%3A%22CDB6899B-7F22-42C6-BCAD-2F0F81602DE1%22%2C%22scm%22%3A%2220140713.130102334.pc%5Fall.%22%7D&amp;request_id=CDB6899B-7F22-42C6-BCAD-2F0F81602DE1&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~rank_v31_ecpm-4-122951888-null-null.142^v100^pc_search_result_base3&amp;utm_term=soft prompt and hard prompt&amp;spm=1018.2226.3001.4187">【调研】Soft Prompt Tuning 模型发展调研：P-tuning,Prefix-tuning,Prompt-tuning,P-tuning v2,PPT-CSDN博客</a></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="http://example.com">Dingming Li</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2024/11/08/[%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0]ATTEMPT-%E9%80%9A%E8%BF%87%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%B7%B7%E5%90%88%E8%BD%AF%E6%8F%90%E7%A4%BA%E8%BF%9B%E8%A1%8C%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E8%B0%83%E6%95%B4/">http://example.com/2024/11/08/[%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0]ATTEMPT-%E9%80%9A%E8%BF%87%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%B7%B7%E5%90%88%E8%BD%AF%E6%8F%90%E7%A4%BA%E8%BF%9B%E8%A1%8C%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E8%B0%83%E6%95%B4/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="http://example.com" target="_blank">碎碎念的博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E5%BE%AE%E8%B0%83/">参数高效微调</a><a class="post-meta__tags" href="/tags/LLM/">LLM</a></div><div class="post-share"><div class="social-share" data-image="/img/butterfly-icon.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2024/10/09/%E4%B8%80%E4%BA%9B%E7%A2%8E%E7%A2%8E%E5%BF%B5/" title="一些碎碎念"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">一些碎碎念</div></div><div class="info-2"><div class="info-item-1">冲冲冲​                转眼就是大三学生了，回过头来看我大一入学为自己的高中写的文章，只能说感慨万千了。  ​                回顾自己的高中生活，这段时光里充满了汗水、欢笑、泪水和成长。在这里，我学到了很多宝贵的学科知识，遇到了很多的真心伙伴，感到了生活的酸甜苦辣。在当时叫体味，到现在叫回味，一位著名导演曾认为，一部好的电影需靠余味来定输赢，人生又何尝不如此，当我走过这段飞扬跋扈的美好时光，又有多少余味在我心头萦绕，又有多少时光我真正成长，又有多少回头仍然值得。到了现在，我更是深知高中时光的璀璨与宝贵，我在脑海中翻涌过往的画面，余味正佳、记忆犹浓。这当然不是朝花夕拾，更像是朝花初嗅的感觉，也希望这种感觉不会消散，伴我成长。 ​               ...</div></div></div></a><a class="pagination-related" href="/2025/01/22/%5B%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0%5DVSI-Bench%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%A6%82%E4%BD%95%E8%A7%82%E5%AF%9F%E3%80%81%E8%AE%B0%E5%BF%86%E5%92%8C%E5%9B%9E%E5%BF%86%E7%A9%BA%E9%97%B4/" title="[论文学习]VSI-Bench:多模态大型语言模型如何观察、记忆和回忆空间"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">[论文学习]VSI-Bench:多模态大型语言模型如何观察、记忆和回忆空间</div></div><div class="info-2"><div class="info-item-1">[论文学习]VSI-Bench:多模态大型语言模型如何观察、记忆和回忆空间资料 论文： Thinking in Space: How Multimodal Large Language Models See, Remember, and Recall Spaces 代码：vision-x-nyu/thinking-in-space: Official repo and evaluation implementation of VSI-Bench 数据集：nyu-visionx/VSI-Bench · Datasets at Hugging Face  简介​       ...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/03/05/%5B%E6%A6%82%E8%BF%B0%E5%AD%A6%E4%B9%A0%5D%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9C%A8%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E5%8D%9A%E5%BC%88%E4%B8%AD%E7%9A%84%E6%8E%A8%E7%90%86%E8%83%BD%E5%8A%9B/" title="[概述学习]语言模型在多智能体博弈中的推理能力"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-03-05</div><div class="info-item-2">[概述学习]语言模型在多智能体博弈中的推理能力</div></div><div class="info-2"><div class="info-item-1">[概述学习]语言模型在多智能体博弈中的推理能力 转载自语言模型在多智能体博弈中的推理能力-CSDN博客  关键词 语言模型 多智能体博弈 推理能力 深度学习 策略学习  摘要​        本文探讨了语言模型在多智能体博弈中的推理能力。通过分析语言模型的原理和多智能体博弈的特点，我们探讨了语言模型在博弈中的具体应用场景和推理过程。文章首先介绍了语言模型和多智能体博弈的基本概念，然后详细阐述了语言模型在多智能体博弈中的推理算法，最后通过具体案例展示了语言模型在博弈中的应用效果。 第一部分：背景介绍1.1 问题背景​       ...</div></div></div></a><a class="pagination-related" href="/2025/03/04/%5B%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0%5DLLMs%E7%9A%84%E5%BF%83%E7%81%B5%E4%B9%8B%E7%9C%BC%EF%BC%9A%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%AD%E6%80%9D%E7%BB%B4%E8%AF%B1%E5%AF%BC%E7%A9%BA%E9%97%B4%E6%8E%A8%E7%90%86%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96/" title="[论文学习]LLMs的心灵之眼：大型语言模型中思维诱导空间推理的可视化"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-03-04</div><div class="info-item-2">[论文学习]LLMs的心灵之眼：大型语言模型中思维诱导空间推理的可视化</div></div><div class="info-2"><div class="info-item-1">[论文学习]LLMs的心灵之眼：大型语言模型中思维诱导空间推理的可视化资料 主页：Mind’s eye of LLMs Vot 论文：[2404.03622] Mind’s Eye of LLMs: Visualization-of-Thought Elicits Spatial Reasoning in Large Language Models 代码：microsoft/visualization-of-thought: [NeurIPS 2024]Repos for “Visualization-of-Thought” dataset, construction code and evaluation.  简介2024年的NeurIPS会议 ​        论文提出了一种名为“Visualization-of-Thought（VoT）”的提示方法，旨在通过可视化大型语言模型（LLMs）的推理过程来激发其空间推理能力。人类在进行空间推理时，能够通过“心灵之眼”（Mind’s...</div></div></div></a><a class="pagination-related" href="/2025/03/06/%5B%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0%5DSCoRe%EF%BC%9A%E9%80%9A%E8%BF%87%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%AE%A9LLM%E5%AD%A6%E4%BC%9A%E8%87%AA%E6%88%91%E7%BA%A0%E6%AD%A3/" title="[论文学习]SCoRe：通过强化学习让LLM学会自我纠正"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-03-06</div><div class="info-item-2">[论文学习]SCoRe：通过强化学习让LLM学会自我纠正</div></div><div class="info-2"><div class="info-item-1">[论文学习]SCoRe：通过强化学习让LLM学会自我纠正资料 论文：[2409.12917] Training Language Models to Self-Correct via Reinforcement Learning  简介​        本文提出了一种名为 SCoRe 的多轮在线强化学习方法，以提升大型语言模型（LLMs）的自我纠正能力，避免依赖额外的监督或更强的模型。研究表明，传统的监督微调（SFT）方法在训练自我纠正时常遇到分布不匹配或行为坍缩的问题，使得模型无法有效改正自身错误。SCoRe 通过在模型自身生成的错误更正轨迹上进行训练，并结合适当的正则化，成功避免这些问题。该方法在 MATH 和 HumanEval 任务上显著提升了 Gemini 1.0 Pro 和 1.5 Flash 模型的自我纠正性能，分别提高了 15.6% 和 9.1%。论文还通过实验分析了传统 SFT 失败的原因，并证明强化学习在训练自我纠正能力方面的必要性。 ​       ...</div></div></div></a><a class="pagination-related" href="/2025/03/06/%5B%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0%5DS%C2%B2R%EF%BC%9A%E9%80%9A%E8%BF%87%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E6%95%99%E4%BC%9A%20LLM%20%E8%87%AA%E6%88%91%E9%AA%8C%E8%AF%81%E5%92%8C%E8%87%AA%E6%88%91%E4%BF%AE%E6%AD%A3/" title="[论文学习]S²R：通过强化学习教会 LLM 自我验证和自我修正"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-03-06</div><div class="info-item-2">[论文学习]S²R：通过强化学习教会 LLM 自我验证和自我修正</div></div><div class="info-2"><div class="info-item-1">[论文学习]S²R：通过强化学习教会 LLM 自我验证和自我修正资料 论文：[2502.12853] S$^2$R: Teaching LLMs to Self-verify and Self-correct via Reinforcement Learning 代码：NineAbyss/S2R: This is the official implementation of the paper “S²R: Teaching LLMs to Self-verify and Self-correct via Reinforcement Learning”  简介​        本文提出了一种名为S²R的方法，以提高大型语言模型（LLMs）的推理能力。S²R 通过两阶段训练：首先，使用监督微调（SFT）让模型学习自我验证和自我纠正的行为；然后，通过基于强化学习（RL）的优化进一步增强这些能力。实验表明，即使在训练数据有限的情况下，S²R 也能显著提升 LLMs...</div></div></div></a><a class="pagination-related" href="/2025/03/05/%5B%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0%5D%E8%AF%AD%E8%A8%80%E7%AD%96%E7%95%A5%E7%9A%84%E5%8D%9A%E5%BC%88%E8%AE%BA%E6%96%B0%E5%A2%83%E7%95%8C%EF%BC%9A%E4%BB%8E%E5%AF%B9%E8%AF%9D%E5%88%B0%E5%B9%B3%E8%A1%A1%E2%80%94%E2%80%94%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8D%9A%E5%BC%88%E8%A7%A3%E6%9E%84%E4%B8%8E%E5%89%8D%E7%9E%BB/" title="[论文学习]语言策略的博弈论新境界：从对话到平衡——大语言模型的博弈解构与前瞻"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-03-05</div><div class="info-item-2">[论文学习]语言策略的博弈论新境界：从对话到平衡——大语言模型的博弈解构与前瞻</div></div><div class="info-2"><div class="info-item-1">[论文学习]语言策略的博弈论新境界：从对话到平衡——大语言模型的博弈解构与前瞻 转载自语言策略的博弈论新境界：从对话到平衡——大语言模型的博弈解构与前瞻-CSDN博客  资料 论文：[2402.01704] Steering Language Models with Game-Theoretic Solvers 代码：open_spiel/open_spiel/python/games/chat_game.py at master · google-deepmind/open_spiel  ​        在人工智能日新月异的发展中，我们常见到一台台大语言模型（LLM）在聊天、问答与创作中大放异彩。然而，在这些机智回答的背后，却隐藏着一个尚未充分挖掘的秘密：对话不仅仅是文字的堆砌，更是一场复杂的多主体战略博弈。最新研究《States as Strings as Strategies: Steering Language Models with Game-Theoretic...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/butterfly-icon.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Dingming Li</div><div class="author-info-description"></div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">14</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">8</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">2</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0%EF%BC%9AATTEMPT-%E9%80%9A%E8%BF%87%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%B7%B7%E5%90%88%E8%BD%AF%E6%8F%90%E7%A4%BA%E8%BF%9B%E8%A1%8C%E5%8F%82%E6%95%B0%E9%AB%98%E6%95%88%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E8%B0%83%E6%95%B4"><span class="toc-number">1.</span> <span class="toc-text">论文学习：ATTEMPT:通过注意力混合软提示进行参数高效的多任务调整</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%B5%84%E6%96%99"><span class="toc-number">1.1.</span> <span class="toc-text">资料</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%89%8D%E7%BD%AE%E7%9F%A5%E8%AF%86"><span class="toc-number">1.2.</span> <span class="toc-text">前置知识</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%AB%98%E6%95%88%E5%8F%82%E6%95%B0%E5%BE%AE%E8%B0%83"><span class="toc-number">1.2.1.</span> <span class="toc-text">高效参数微调</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#BitFit"><span class="toc-number">1.2.2.</span> <span class="toc-text">BitFit</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Prefix-Tuning"><span class="toc-number">1.2.3.</span> <span class="toc-text">Prefix Tuning</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Prompt-Tuning"><span class="toc-number">1.2.4.</span> <span class="toc-text">Prompt Tuning</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#P-Tuning"><span class="toc-number">1.2.5.</span> <span class="toc-text">P-Tuning</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#P-Tuning-v2"><span class="toc-number">1.2.6.</span> <span class="toc-text">P-Tuning v2</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#SPoT"><span class="toc-number">1.2.7.</span> <span class="toc-text">SPoT</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%BA%E6%96%87%E5%A4%A7%E4%BD%93%E4%BB%8B%E7%BB%8D"><span class="toc-number">1.3.</span> <span class="toc-text">论文大体介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%BA%E6%96%87%E8%83%8C%E6%99%AF"><span class="toc-number">1.4.</span> <span class="toc-text">论文背景</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%96%B9%E6%B3%95%E5%8E%9F%E7%90%86"><span class="toc-number">1.5.</span> <span class="toc-text">方法原理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E8%AE%BE%E7%BD%AE"><span class="toc-number">1.6.</span> <span class="toc-text">实验设置</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E7%BB%93%E8%AE%BA"><span class="toc-number">1.7.</span> <span class="toc-text">实验结论</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">1.8.</span> <span class="toc-text">总结</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%98%E7%82%B9"><span class="toc-number">1.8.1.</span> <span class="toc-text">优点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%BA%E7%82%B9"><span class="toc-number">1.8.2.</span> <span class="toc-text">缺点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%94%B9%E8%BF%9B"><span class="toc-number">1.8.3.</span> <span class="toc-text">改进</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E8%80%83"><span class="toc-number">1.9.</span> <span class="toc-text">参考</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/03/07/%5B%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0%5DMM-EGO%EF%BC%9A%E8%BF%88%E5%90%91%E6%9E%84%E5%BB%BA%E4%BB%A5%E8%87%AA%E6%88%91%E4%B8%BA%E4%B8%AD%E5%BF%83%E7%9A%84%E5%A4%9A%E6%A8%A1%E6%80%81LLMS/" title="[论文学习]MM-EGO：迈向构建以自我为中心的多模态LLMS">[论文学习]MM-EGO：迈向构建以自我为中心的多模态LLMS</a><time datetime="2025-03-07T10:46:14.000Z" title="发表于 2025-03-07 18:46:14">2025-03-07</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/03/06/%5B%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0%5DSCoRe%EF%BC%9A%E9%80%9A%E8%BF%87%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E8%AE%A9LLM%E5%AD%A6%E4%BC%9A%E8%87%AA%E6%88%91%E7%BA%A0%E6%AD%A3/" title="[论文学习]SCoRe：通过强化学习让LLM学会自我纠正">[论文学习]SCoRe：通过强化学习让LLM学会自我纠正</a><time datetime="2025-03-06T11:14:51.000Z" title="发表于 2025-03-06 19:14:51">2025-03-06</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/03/06/%5B%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0%5DS%C2%B2R%EF%BC%9A%E9%80%9A%E8%BF%87%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E6%95%99%E4%BC%9A%20LLM%20%E8%87%AA%E6%88%91%E9%AA%8C%E8%AF%81%E5%92%8C%E8%87%AA%E6%88%91%E4%BF%AE%E6%AD%A3/" title="[论文学习]S²R：通过强化学习教会 LLM 自我验证和自我修正">[论文学习]S²R：通过强化学习教会 LLM 自我验证和自我修正</a><time datetime="2025-03-06T09:24:35.000Z" title="发表于 2025-03-06 17:24:35">2025-03-06</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/03/05/%5B%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0%5DSpatialRGPT%EF%BC%9A%E8%A7%86%E8%A7%89%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E4%B8%AD%E8%90%BD%E5%9C%B0%E7%A9%BA%E9%97%B4%E6%8E%A8%E7%90%86/" title="[论文学习]SpatialRGPT：视觉语言模型中落地空间推理">[论文学习]SpatialRGPT：视觉语言模型中落地空间推理</a><time datetime="2025-03-05T14:23:16.000Z" title="发表于 2025-03-05 22:23:16">2025-03-05</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/03/05/%5B%E6%A6%82%E8%BF%B0%E5%AD%A6%E4%B9%A0%5D%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9C%A8%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E5%8D%9A%E5%BC%88%E4%B8%AD%E7%9A%84%E6%8E%A8%E7%90%86%E8%83%BD%E5%8A%9B/" title="[概述学习]语言模型在多智能体博弈中的推理能力">[概述学习]语言模型在多智能体博弈中的推理能力</a><time datetime="2025-03-05T08:13:45.000Z" title="发表于 2025-03-05 16:13:45">2025-03-05</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2025 By Dingming Li</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.3.5</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>